{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries\n",
    "\n",
    "import zipfile, re, logging\n",
    "from io import BytesIO\n",
    "import re\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Extracting a ZIP File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Script to extract all the nested zip files\n",
    "\n",
    "with zipfile.ZipFile(\"Data.zip\", \"r\") as zfile:\n",
    "    for name in zfile.namelist():\n",
    "        if re.search(r'\\.zip$', name) is not None:\n",
    "            zfiledata = BytesIO(zfile.read(name))\n",
    "            #zfile.extractall()\n",
    "            with zipfile.ZipFile(zfiledata) as zfile2:\n",
    "                zfile2.extractall(\"./Data/\")                    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Extracting Some Information from XML Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting some information from xml file\n",
    "\n",
    "listText = []\n",
    "listHeadlines = []\n",
    "listFileName = []\n",
    "listItemID = []\n",
    "\n",
    "for filename in os.listdir('./Data/'):\n",
    "    if filename.endswith('.xml'):\n",
    "        with open(os.path.join('./Data/', filename)) as f:\n",
    "            strings = f.read() \n",
    "            f.close()\n",
    "            matchesText = re.findall(r\"(?<=<text>).*?(?=</text>)\", strings, flags=re.DOTALL)\n",
    "            matchesHeadlines = re.findall(r\"(?<=<headline>).*?(?=</headline>)\", strings, flags=re.DOTALL)\n",
    "            matchesItemID = re.findall(r\"<newsitem(?:\\D+=\\\"\\S*\\\")*\\s+itemid=\\\"(\\d*)\\\"\", strings, flags=re.DOTALL)\n",
    "            for text in matchesText:\n",
    "                listText.append(text)\n",
    "            for headline in matchesHeadlines:\n",
    "                listHeadlines.append(headline)\n",
    "            listFileName.append(filename)\n",
    "            for itemid in matchesItemID:\n",
    "                listItemID.append(itemid)    \n",
    "# removing some tags/characetrs from text\n",
    "\n",
    "listText = [txt.replace('<p>', ' ').replace('</p>', ' ').replace('\\n', ' ') for txt in listText]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "listTopics = []\n",
    "listTemp = []\n",
    "listPublishedDate = []\n",
    "ListBipTopics = []\n",
    "\n",
    "for filename in os.listdir('./Data/'):\n",
    "    if filename.endswith('.xml'):\n",
    "        with open(os.path.join('./Data/', filename)) as f:\n",
    "            strings = f.read() \n",
    "            soup = BeautifulSoup(strings)\n",
    "            listset=soup(\"codes\",\"bip:topics:1.0\")\n",
    "            for top in listset:\n",
    "                listTemp += [a['code'] for a in top.findAll('code',{'code':True})]\n",
    "            listTopics.append(listTemp)\n",
    "            listTemp =[]    \n",
    "            \n",
    "            inputTag = soup(attrs={\"element\" : \"dc.date.published\"})\n",
    "            output = inputTag[0]['value']\n",
    "            listPublishedDate.append(output)\n",
    "\n",
    "for sublist in listTopics:\n",
    "    s = [str(i) for i in sublist]   \n",
    "    res = \",\".join(s) \n",
    "    ListBipTopics.append(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Extracting a Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractDataframe(HeadlinesList, TextList, BitopicsList, PublishedDateList, ItemIDList, FileNamesList, columnsList):\n",
    "    df = pd.DataFrame(list(zip(HeadlinesList,TextList,BitopicsList,PublishedDateList,ItemIDList,FileNamesList)), columns=columnsList)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['HeadLine','Text','Bi:Topics','Date Published','Itemid','XMLfileName']\n",
    "df = extractDataframe(listHeadlines,listText,ListBipTopics,listPublishedDate,listItemID,listFileName,columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HeadLine</th>\n",
       "      <th>Text</th>\n",
       "      <th>Bi:Topics</th>\n",
       "      <th>Date Published</th>\n",
       "      <th>Itemid</th>\n",
       "      <th>XMLfileName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Canadian Occidental mounts rival Wascana bid.</td>\n",
       "      <td>Canadian Occidental Petroleum Ltd. emerged o...</td>\n",
       "      <td>C181</td>\n",
       "      <td>1997-03-18</td>\n",
       "      <td>326914</td>\n",
       "      <td>326914newsML.xml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gruma, Maseca to receive syndicated loan - bank.</td>\n",
       "      <td>Bank of America will launch a three-year $12...</td>\n",
       "      <td>C173</td>\n",
       "      <td>1997-03-18</td>\n",
       "      <td>326915</td>\n",
       "      <td>326915newsML.xml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Too early to call Krupp bid hostile - Deutsche...</td>\n",
       "      <td>Deutsche Bank AG management board member Rol...</td>\n",
       "      <td>C18,C181,CCAT</td>\n",
       "      <td>1997-03-18</td>\n",
       "      <td>326916</td>\n",
       "      <td>326916newsML.xml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FOCUS - Euro bourses fret over Wall St, electi...</td>\n",
       "      <td>European bourses fell on Tuesday even before...</td>\n",
       "      <td>M11,M13,M132,M14,M142,MCAT</td>\n",
       "      <td>1997-03-18</td>\n",
       "      <td>326917</td>\n",
       "      <td>326917newsML.xml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>French stocks fall, Alcatel posts big gain.</td>\n",
       "      <td>French shares closed lower on Tuesday in the...</td>\n",
       "      <td>G152,M11</td>\n",
       "      <td>1997-03-18</td>\n",
       "      <td>326918</td>\n",
       "      <td>326918newsML.xml</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            HeadLine  \\\n",
       "0      Canadian Occidental mounts rival Wascana bid.   \n",
       "1   Gruma, Maseca to receive syndicated loan - bank.   \n",
       "2  Too early to call Krupp bid hostile - Deutsche...   \n",
       "3  FOCUS - Euro bourses fret over Wall St, electi...   \n",
       "4        French stocks fall, Alcatel posts big gain.   \n",
       "\n",
       "                                                Text  \\\n",
       "0    Canadian Occidental Petroleum Ltd. emerged o...   \n",
       "1    Bank of America will launch a three-year $12...   \n",
       "2    Deutsche Bank AG management board member Rol...   \n",
       "3    European bourses fell on Tuesday even before...   \n",
       "4    French shares closed lower on Tuesday in the...   \n",
       "\n",
       "                    Bi:Topics Date Published  Itemid       XMLfileName  \n",
       "0                        C181     1997-03-18  326914  326914newsML.xml  \n",
       "1                        C173     1997-03-18  326915  326915newsML.xml  \n",
       "2               C18,C181,CCAT     1997-03-18  326916  326916newsML.xml  \n",
       "3  M11,M13,M132,M14,M142,MCAT     1997-03-18  326917  326917newsML.xml  \n",
       "4                    G152,M11     1997-03-18  326918  326918newsML.xml  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Finding Unique Values for Bi:Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnNames = ['code','topic']\n",
    "codes = pd.read_csv('./Data/topic_codes.txt', sep=\"\\t\", engine=\"python\", names = columnNames)\n",
    "codes.drop(codes.index[[0,1]],inplace=True)\n",
    "dictTopics = dict(zip(codes.code, codes.topic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "listAllTopics = []\n",
    "uniqueTpoics = []\n",
    "\n",
    "# function to get unique topics\n",
    "def uniqueTopics(dataframe, columnName):\n",
    "    for element in dataframe[columnName]:\n",
    "        strings = element.split(',')\n",
    "        listAllTopics.append(strings)\n",
    "        flatList = [ item for elem in listAllTopics for item in elem]\n",
    "    for item in flatList: \n",
    "        if item not in uniqueTpoics: \n",
    "            uniqueTpoics.append(item) \n",
    "    return uniqueTpoics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Total Number of Unique Topics 103 n\n",
      "All Possible Values for bi:topics are given bellow \n",
      "\n",
      " ['MERGERS/ACQUISITIONS', 'LOANS/CREDITS', 'OWNERSHIP CHANGES', 'CORPORATE/INDUSTRIAL', 'EQUITY MARKETS', 'MONEY MARKETS', 'FOREX MARKETS', 'COMMODITY MARKETS', 'METALS TRADING', 'MARKETS', 'EC CORPORATE POLICY', 'SOFT COMMODITIES', 'GOVERNMENT/SOCIAL', 'DOMESTIC POLITICS', 'WAR, CIVIL WAR', 'DISASTERS AND ACCIDENTS', 'BIOGRAPHIES, PERSONALITIES, PEOPLE', 'RELIGION', 'BOND MARKETS', 'PERFORMANCE', 'ACCOUNTS/EARNINGS', 'LEADING INDICATORS', 'ECONOMICS', 'STRATEGY/PLANS', 'CRIME, LAW ENFORCEMENT', 'CONTRACTS/ORDERS', 'FUNDING/CAPITAL', 'SHARE CAPITAL', 'REGULATION/POLICY', 'EUROPEAN COMMUNITY', 'EC AGRICULTURE POLICY', 'GOVERNMENT FINANCE', 'EXPENDITURE/REVENUE', 'EC MONETARY/ECONOMIC', 'EC EXTERNAL RELATIONS', 'DEFENCE', 'INTERNATIONAL RELATIONS', 'ECONOMIC PERFORMANCE', 'MARKETS/MARKETING', 'CAPACITY/FACILITIES', 'MONETARY/ECONOMIC', 'INTERBANK MARKETS', 'COMMENT/FORECASTS', 'LABOUR', 'EMPLOYMENT/LABOUR', 'LABOUR ISSUES', 'PRIVATISATIONS', 'ANNUAL RESULTS', 'UNEMPLOYMENT', 'DOMESTIC MARKETS', 'ENERGY MARKETS', 'PRODUCTION/SERVICES', 'EC INTERNAL MARKET', 'TRADE/RESERVES', 'INFLATION/PRICES', 'CONSUMER PRICES', 'MERCHANDISE TRADE', 'NEW PRODUCTS/SERVICES', 'EC INSTITUTIONS', 'GOVERNMENT BORROWING', 'WELFARE, SOCIAL SERVICES', 'ASSET TRANSFERS', 'MANAGEMENT', 'MANAGEMENT MOVES', 'MONOPOLIES/COMPETITION', 'LEGAL/JUDICIAL', 'CREDIT RATINGS', 'ADVERTISING/PROMOTION', 'HEALTH', 'WEATHER', 'OUTPUT/CAPACITY', 'INDUSTRIAL PRODUCTION', 'RESEARCH/DEVELOPMENT', 'SHARE LISTINGS', 'MONEY SUPPLY', 'RESERVES', 'BONDS/DEBT ISSUES', 'INSOLVENCY/LIQUIDITY', 'SPORTS', 'BALANCE OF PAYMENTS', 'ARTS, CULTURE, ENTERTAINMENT', 'SCIENCE AND TECHNOLOGY', 'ELECTIONS', 'ENVIRONMENT AND NATURAL WORLD', '', 'EXTERNAL MARKETS', 'HUMAN INTEREST', 'DEFENCE CONTRACTS', 'TRAVEL AND TOURISM', 'EC COMPETITION/SUBSIDY', 'HOUSING STARTS', 'FASHION', 'OBITUARIES', 'MARKET SHARE', 'WHOLESALE PRICES', 'EC ENVIRONMENT ISSUES', 'CONSUMER FINANCE', 'RETAIL SALES', 'INVENTORIES', 'CONSUMER CREDIT', 'PERSONAL INCOME', 'CAPACITY UTILIZATION', 'EC GENERAL']\n"
     ]
    }
   ],
   "source": [
    "listUniqueTopics = uniqueTopics(df, 'Bi:Topics')\n",
    "headersList = [ dictTopics.get(item,item) for item in listUniqueTopics ]\n",
    "\n",
    "print(\"The Total Number of Unique Topics\",len(headersList),\"n\\nAll Possible Values for bi:topics are given bellow \\n\\n\",headersList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Preprocessing the Text Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessedData(dataframe, textColumn):\n",
    "    dataframe[textColumn] = dataframe[textColumn].map(lambda x: re.sub(r'\\W+', ' ', x))   #removing special character\n",
    "    dataframe[textColumn] = dataframe[textColumn].map(lambda x: re.sub(r'\\d+', '', x))    # removing all the digits\n",
    "    dataframe[textColumn] = dataframe[textColumn].map(lambda x: x.lower())                # converting into lower case\n",
    "\n",
    "    # tokenize the words\n",
    "    dataframe[textColumn] = dataframe[textColumn].map(lambda x: nltk.word_tokenize(x))\n",
    "\n",
    "    # remove stop words\n",
    "    stop = stopwords.words('english')\n",
    "    dataframe[textColumn] = dataframe[textColumn].map(lambda x: [item for item in x if item not in stop])\n",
    "\n",
    "    #lemmatization\n",
    "    lemmatizer=WordNetLemmatizer()\n",
    "    dataframe[textColumn] = dataframe[textColumn].map(lambda x: [lemmatizer.lemmatize(item) for item in x])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessedData(df,'Text')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Extracting Features and Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def featureExtraction(dataframe, textColumn, topicsColumn):\n",
    "    countVect = CountVectorizer(tokenizer=lambda x: x, lowercase=False).fit_transform(dataframe[textColumn])\n",
    "    tfidfTrans = TfidfTransformer()\n",
    "    tfidfOfText = tfidfTrans.fit_transform(countVect)\n",
    "    print(\"Features Shape\",tfidfOfText.shape)\n",
    "    dataframe[topicsColumn]=dataframe[topicsColumn].str.split(',').str[0]\n",
    "    dataframe[topicsColumn] = dataframe[topicsColumn].astype('category')\n",
    "    dataframe[topicsColumn] = dataframe[topicsColumn].cat.codes\n",
    "    print(\"Target Shape\",dataframe[topicsColumn].shape)\n",
    "    return tfidfOfText,dataframe[topicsColumn]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features Shape (48375, 92535)\n",
      "Target Shape (48375,)\n"
     ]
    }
   ],
   "source": [
    "Features, Target= featureExtraction(df,'Text','Bi:Topics')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Dividing the Dataset using Train/Test Split\n",
    "\n",
    "Dividing the Dataset into train and test is necessary to check how well the model generlize the data. we need some kind assurity that model fits the pattern of data well, in other words, the value of bias and variance.\n",
    "\n",
    "Here I am using Train/Test validation method rather than cross validation, to split the data as it is very simple to use. Cross Validation mostly used when we have very less number of data or to set the hyperparameters. Hence, If we have enough amount of data, Train/Test is a better method to split the data for faster implementation of algorithm as well as to avoid comuptational cost ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function to split the data into Train and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "def splitDataset(Feature, Target, testSize, randomState):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(Feature, Target, test_size=testSize, random_state=randomState)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. A function to Generate Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateClassifier(features, labels, classifier,gamma='scale',kernel='linear',estimators=200):\n",
    "    X_train, X_test, y_train, y_test = splitDataset(features, labels, 0.3, 25)\n",
    "    if(classifier == DecisionTreeClassifier):\n",
    "        clf = classifier()\n",
    "    elif(classifier == SVC):\n",
    "        clf = classifier(gamma=gamma, kernel=kernel)\n",
    "    elif(classifier == RandomForestClassifier):\n",
    "        clf = classifier(n_estimators=estimators)\n",
    "    elif(classifier == LinearRegression):\n",
    "        clf = classifier()\n",
    "    \n",
    "    clf = clf.fit(X_train, y_train)\n",
    "    predicted = clf.predict(X_test)\n",
    "    return predicted, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. A Function for Evaluating a Model\n",
    "\n",
    "Here, I am using Accuracy score to evaluate the model to check ho well the model is doing on the test dataset.\n",
    "Accuracy score- Because it is a classification problem.\n",
    "\n",
    "-> Why Accuracy Measument? - To know how well the model will perform in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateModel(y_test, predictedValues):\n",
    "    accuracyScore = np.mean(predictedValues == y_test)\n",
    "    return accuracyScore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. Implementing Five Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Accuracy for Decision Tree model is 0.6340522290360366\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "valuesPredicated, y_test = generateClassifier(Features, Target, DecisionTreeClassifier)\n",
    "accuracyScoreDT = evaluateModel(y_test, valuesPredicated)\n",
    "print(\"The Accuracy for Decision Tree model is\", accuracyScoreDT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Accuracy for SVM model is 0.8047267966650589\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "valuesPredicatedSVM, y_test = generateClassifier(Features, Target, SVC)\n",
    "accuracyScoreSVC = evaluateModel(y_test, valuesPredicatedSVM)\n",
    "print(\"The Accuracy for SVM model is\", accuracyScoreSVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Accuracy for Random Forest model is 0.7283814511127954\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "valuesPredicatedRF, y_test = generateClassifier(Features, Target, RandomForestClassifier,200)\n",
    "accuracyScoreRF = evaluateModel(y_test, valuesPredicatedRF)\n",
    "print(\"The Accuracy for Random Forest model is\", accuracyScoreRF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Accuracy for Random Forest model is 0.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "valuesPredicatedLR, y_test = generateClassifier(Features, Target, LinearRegression)\n",
    "accuracyScoreLR = evaluateModel(y_test, valuesPredicatedLR)\n",
    "print(\"The Accuracy for Random Forest model is\", accuracyScoreLR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33862, 92535)\n",
      "(14513, 92535)\n",
      "(33862, 103)\n",
      "(14513, 103)\n",
      "Train on 33862 samples, validate on 14513 samples\n",
      "Epoch 1/10\n",
      "33862/33862 [==============================] - 109s 3ms/step - loss: 1.6893 - acc: 0.5807 - val_loss: 1.0376 - val_acc: 0.7199\n",
      "Epoch 2/10\n",
      "33862/33862 [==============================] - 109s 3ms/step - loss: 0.6231 - acc: 0.8339 - val_loss: 0.9210 - val_acc: 0.7568\n",
      "Epoch 3/10\n",
      "33862/33862 [==============================] - 109s 3ms/step - loss: 0.2740 - acc: 0.9301 - val_loss: 1.0514 - val_acc: 0.7609\n",
      "Epoch 4/10\n",
      "33862/33862 [==============================] - 108s 3ms/step - loss: 0.1560 - acc: 0.9594 - val_loss: 1.2600 - val_acc: 0.7278\n",
      "Epoch 5/10\n",
      "33862/33862 [==============================] - 116s 3ms/step - loss: 0.1165 - acc: 0.9687 - val_loss: 1.2343 - val_acc: 0.7523\n",
      "Epoch 6/10\n",
      "33862/33862 [==============================] - 114s 3ms/step - loss: 0.0929 - acc: 0.9740 - val_loss: 1.3054 - val_acc: 0.7553\n",
      "Epoch 7/10\n",
      "33862/33862 [==============================] - 109s 3ms/step - loss: 0.0810 - acc: 0.9771 - val_loss: 1.5859 - val_acc: 0.7238\n",
      "Epoch 8/10\n",
      "33862/33862 [==============================] - 108s 3ms/step - loss: 0.0721 - acc: 0.9783 - val_loss: 1.3720 - val_acc: 0.7583\n",
      "Epoch 9/10\n",
      "33862/33862 [==============================] - 108s 3ms/step - loss: 0.0655 - acc: 0.9795 - val_loss: 1.3946 - val_acc: 0.7569\n",
      "Epoch 10/10\n",
      "33862/33862 [==============================] - 109s 3ms/step - loss: 0.0626 - acc: 0.9799 - val_loss: 1.4009 - val_acc: 0.7544\n",
      "14513/14513 [==============================] - 24s 2ms/step\n",
      "Test Loss Value: 1.400886609997352 Test Accuracy Score: 0.7543581616604984\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import models, layers, optimizers, datasets, utils\n",
    "\n",
    "X_train, X_test, y_train, y_test = splitDataset(Features, Target, 0.3, 25)\n",
    "y_train = utils.to_categorical(y_train, 103)\n",
    "y_test = utils.to_categorical(y_test, 103)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "mlpInputs = layers.Input(shape=(92535,))\n",
    "n = layers.Dense(128, activation='relu')(mlpInputs)\n",
    "n = layers.Dense(128, activation='relu')(n)\n",
    "n = layers.Dense(128, activation='relu')(n)\n",
    "n = layers.Dense(128, activation='relu')(n)\n",
    "outcomes= layers.Dense(103, activation='softmax')(n)\n",
    "\n",
    "mlpModel = models.Model(inputs=mlpInputs, outputs=outcomes)\n",
    "\n",
    "mlpModel.compile(loss='categorical_crossentropy',\n",
    "              optimizer='Nadam', metrics=['accuracy'])\n",
    "\n",
    "history=mlpModel.fit(X_train, y_train, batch_size=256, epochs=10, validation_data=(X_test, y_test))\n",
    "valScore = mlpModel.evaluate(X_test, y_test)\n",
    "print('Test Loss Value:', valScore[0],'Test Accuracy Score:', valScore[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GriSearch for Tuning the HyperParameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "X_train, X_test, y_train, y_test = splitDataset(Features, Target, 0.3, 25)\n",
    "\n",
    "svm = SVC()\n",
    "params = {\n",
    "        'kernel':['linear','poly','sigmoid'],\n",
    "        'gamma': ['auto', 'scale']\n",
    "        }\n",
    "grid = GridSearchCV(svm, params)\n",
    "grid.fit(X_train,y_train)\n",
    "grid.best_params_  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Accuracy for SVM model after hyparameter tuning is 0.810452527329295\n"
     ]
    }
   ],
   "source": [
    "predSVM = grid.predict(X_test)\n",
    "accuracyScoreGridSVM = evaluateModel(y_test, predSVM)\n",
    "print(\"The Accuracy for SVM model after hyparameter tuning is\", accuracyScoreGridSVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The best Model is SVM\n",
    "\n",
    "SVM got the highest accuracy out of all the classifiers because it generalizes the complex relationship within the dataset. Although, it takes more time to train the data, SVM is a Robust algorithm- which means that it is not very sensitive to outliers.\n",
    "\n",
    "SVM is not very prone to overfiiting and also SVM is generally used with large number of features, which is the situation over here.\n",
    "\n",
    "All in all, the best algorithm for any dataset is the one, which gives the highest accuracy without over fitting and thats what SVM is doing for the given dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference:\n",
    "[1] https://docs.python.org/3/library/zipfile.html\n",
    "\n",
    "[2] https://www.crummy.com/software/BeautifulSoup/bs4/doc/\n",
    "\n",
    "[3] https://docs.python.org/3/library/functions.html#map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
